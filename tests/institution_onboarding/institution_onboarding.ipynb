{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f20ee26-1814-470c-88a6-76e47cf98bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script automates the onboarding and deletion of institutions within a Databricks workspace,\n",
    "including setting up storage, Unity Catalog schemas and volumes, and copying/deleting ML models.\n",
    "\"\"\"\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service import catalog\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "from google.cloud import storage\n",
    "import random\n",
    "import toml\n",
    "import os\n",
    "\n",
    "# Initialize clients for Databricks, Google Cloud Storage, and MLflow\n",
    "w = WorkspaceClient()\n",
    "storage_client = storage.Client()\n",
    "mlflow_client = MlflowClient()\n",
    "\n",
    "# Configuration variables\n",
    "catalog_name = \"dev_sst_02\"  # Name of the Unity Catalog\n",
    "medallion_levels = [\"silver\", \"gold\", \"bronze\"]  # List of data medallion levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54eefc90-8d37-4d6d-a51a-618d2a94a612",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def onboard_institution(institution_id):\n",
    "    \"\"\"\n",
    "    Onboards a new institution by creating necessary resources.\n",
    "\n",
    "    Args:\n",
    "        institution_id: The ID of the institution to onboard.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a GCS bucket for SST application data.\n",
    "    sst_app_bucket = storage_client.create_bucket(\n",
    "        f\"{catalog_name}_{institution_id}_sst_application\", location=\"us-east4\"\n",
    "    )\n",
    "\n",
    "    # TODO CREATE A SERVICE ACCOUNT PER WORKSPACE\n",
    "\n",
    "    # Grant object admin access to the specified service account.\n",
    "    policy = sst_app_bucket.get_iam_policy(requested_policy_version=3)\n",
    "    policy.bindings.append(\n",
    "        {\n",
    "            \"role\": \"roles/storage.objectAdmin\",\n",
    "            \"members\": {\n",
    "                \"serviceAccount:pedro-pdp-inference-pipeline@dev-sst-02.iam.gserviceaccount.com\"\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    sst_app_bucket.set_iam_policy(policy)\n",
    "\n",
    "    # Create Unity Catalog schemas for each medallion level.\n",
    "    for medallion in medallion_levels:\n",
    "        w.schemas.create(\n",
    "            name=f\"{institution_id}_{medallion}\", catalog_name=catalog_name\n",
    "        )\n",
    "\n",
    "    # Create a managed volume in the bronze schema for internal pipeline data.\n",
    "    w.volumes.create(\n",
    "        catalog_name=catalog_name,\n",
    "        schema_name=f\"{institution_id}_bronze\",\n",
    "        name=\"pdp_pipeline_internal\",\n",
    "        volume_type=catalog.VolumeType.MANAGED,\n",
    "    )\n",
    "\n",
    "    # Create a managed volume in the gold schema for the configuration files (.toml files)\n",
    "    w.volumes.create(\n",
    "        catalog_name=catalog_name,\n",
    "        schema_name=f\"{institution_id}_gold\",\n",
    "        name=\"gold_volume\",\n",
    "        volume_type=catalog.VolumeType.MANAGED,\n",
    "    )\n",
    "\n",
    "    # Copy an existing model to the new institution's bronze schema.  This is a placeholder.\n",
    "    # In a real scenario, models would likely be trained specifically for the institution.\n",
    "    model_name = \"latest_enrollment_model\"\n",
    "    existing_model_uri = f\"models:/{catalog_name}.institution_x_bronze.{model_name}/1\"\n",
    "    new_institution_model_uri = f\"{catalog_name}.{institution_id}_gold.{model_name}\"\n",
    "\n",
    "    mlflow.register_model(existing_model_uri, new_institution_model_uri)\n",
    "\n",
    "    # Creating an institution configuration file copying from a template. This is a placeholder.\n",
    "    # In a real scenario, toml file is specifically built for the institution.\n",
    "    toml_template_path = \"/Workspace/Users/pedro.melendez@datakind.org/repo-student-success-tool-develop/tests/institution_onboarding/template_enrollment_model_toml_file.toml\"\n",
    "    with open(toml_template_path, \"r\") as f:\n",
    "        toml_template = toml.load(f)\n",
    "\n",
    "    toml_template[\"institution_id\"], toml_template[\"institution_name\"] = (\n",
    "        institution_id,\n",
    "        institution_id,\n",
    "    )\n",
    "\n",
    "    # Create directory on the volume\n",
    "    config_file_path = f\"/Volumes/{catalog_name}/{institution_id}_gold/gold_volume/configuration_files/\"\n",
    "    os.makedirs(config_file_path, exist_ok=True)\n",
    "\n",
    "    with open(\n",
    "        f\"{config_file_path}/{institution_id}_{model_name}_configuration_file.toml\", \"w\"\n",
    "    ) as f:\n",
    "        toml.dump(toml_template, f)\n",
    "\n",
    "\n",
    "def delete_institution(institution_id):\n",
    "    \"\"\"\n",
    "    Deletes all resources associated with a given institution.\n",
    "\n",
    "    Args:\n",
    "        institution_id: The ID of the institution to delete.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Delete the GCS bucket.  Force=True handles non-empty buckets.\n",
    "        bucket = storage_client.get_bucket(\n",
    "            f\"{catalog_name}_{institution_id}_sst_application\"\n",
    "        )\n",
    "        bucket.delete(force=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting bucket: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Delete the managed volume.\n",
    "        w.volumes.delete(\n",
    "            name=f\"{catalog_name}.{institution_id}_bronze.pdp_pipeline_internal\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting volume: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Delete the managed volume.\n",
    "        w.volumes.delete(name=f\"{catalog_name}.{institution_id}_gold.gold_volume\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting volume: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Delete the MLflow model.\n",
    "        model_name = \"latest_enrollment_model\"\n",
    "        new_institution_model_uri = f\"{catalog_name}.{institution_id}_gold.{model_name}\"\n",
    "        mlflow_client.delete_registered_model(name=new_institution_model_uri)\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting model: {e}\")\n",
    "\n",
    "    # Delete tables and schemas for each medallion level.\n",
    "    for medallion in medallion_levels:\n",
    "        try:\n",
    "            all_tables = [\n",
    "                table.name\n",
    "                for table in w.tables.list(\n",
    "                    catalog_name=catalog_name,\n",
    "                    schema_name=f\"{institution_id}_{medallion}\",\n",
    "                )\n",
    "            ]\n",
    "            for table in all_tables:\n",
    "                w.tables.delete(\n",
    "                    full_name=f\"{catalog_name}.{institution_id}_{medallion}.{table}\"\n",
    "                )\n",
    "            w.schemas.delete(full_name=f\"{catalog_name}.{institution_id}_{medallion}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting schema or tables for {medallion}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bebaa951-77a0-429a-a406-ddb4a55ef537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example usage (comment out to test)\n",
    "institution_id = \"new_institution_id\"  # Example institution ID.  Should be parameterized in real use cases.\n",
    "print(institution_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47d934bf-411c-4d0e-b883-4781ccbca2d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Onboarding a sample institution\n",
    "onboard_institution(institution_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13abdbf7-8936-4fa5-a97e-6ad6f423b3ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Running an inference job with the new institution\n",
    "\n",
    "job_name = \"pdp_inference_pipeline_on_personal_cluster_pedro\"\n",
    "# job_name = \"PDP_inference_pipeline\"\n",
    "job_id = next(w.jobs.list(name=job_name)).job_id\n",
    "\n",
    "run_job = w.jobs.run_now(\n",
    "    job_id,\n",
    "    job_parameters={\n",
    "        \"synthetic_needed\": \"True\",\n",
    "        \"num_students\": \"450\",\n",
    "        \"institution_id\": institution_id,\n",
    "        \"sst_job_id\": f\"first_inference_job_{institution_id}_inference_job_id_{str(random.randint(1, 1000))}\",\n",
    "    },\n",
    ")\n",
    "print(run_job.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41f550d5-0d38-421e-b4d1-aaa8a8ad4477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example usage (comment out to test)\n",
    "delete_institution(institution_id)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "institution_onboarding",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
